{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import pickle\n",
    "\n",
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=12'\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "#from jax.config import config; config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from brax import envs\n",
    "from brax.io import html, model\n",
    "from brax.training import normalization\n",
    "\n",
    "import flax\n",
    "import jax.numpy as jnp\n",
    "from brax.envs import create_fn\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from controllers import GruController, MlpController, LinearController\n",
    "\n",
    "from ce_apg import do_one_rollout, cem_apg\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def visualize(sys, qps, height=480):\n",
    "  \"\"\"Renders a 3D visualization of the environment.\"\"\"\n",
    "  return HTML(html.render(sys, qps, height=height))\n",
    "\n",
    "len(jax.devices())\n",
    "\n",
    "save_dir = \"save_ce_apg_ant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "learning rate:  0.0010000000474974513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 13:25:54.449830: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:55] \n",
      "********************************\n",
      "Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "Compiling module pmap_do_local_apg.101694\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "env_name = \"ant\" # \"acrobot\", \"inverted_pendulum_swingup\", \"inverted_double_pendulum_swingup\"]:\n",
    "episode_length = 500\n",
    "action_repeat = 1\n",
    "env_fn = create_fn(env_name = env_name, episode_length=episode_length, action_repeat=action_repeat, batch_size=None, auto_reset=False)\n",
    "env = env_fn()\n",
    "\n",
    "policy_size = int(2**jnp.ceil(jnp.log2(env.observation_size*4)))\n",
    "print(policy_size)\n",
    "policy = GruController(env.observation_size, env.action_size, policy_size)\n",
    "pickle.dump(policy, open(f\"{save_dir}/{env_name}_policy\", 'wb'))\n",
    "\n",
    "seed = 0\n",
    "inference_fn, params, rewards = cem_apg(env_fn,\n",
    "                                        20,\n",
    "                                        key=jax.random.PRNGKey(seed),\n",
    "                                        episode_length = episode_length,\n",
    "                                        action_repeat = action_repeat,\n",
    "                                        apg_epochs = 100,\n",
    "                                        batch_size = 1,\n",
    "                                        zero_params=False,\n",
    "                                        truncation_length = None,\n",
    "                                        learning_rate = 1e-4,\n",
    "                                        clipping = 1e9,\n",
    "                                        initial_std = 0.01,\n",
    "                                        num_elite = 8,\n",
    "                                        eps = 0.0,\n",
    "                                        normalize_observations=True,\n",
    "                                        policy = policy,\n",
    "                                        learning_schedule = [-3, -6]\n",
    "                                       )\n",
    "\n",
    "model.save_params(f\"{save_dir}/{env_name}_params_{seed}\", params)\n",
    "pickle.dump(rewards, open(f\"{save_dir}/{env_name}_rewards.pkl{seed}\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax.io import model\n",
    "import ce_apg\n",
    "\n",
    "jit_env_reset = jax.jit(env.reset)\n",
    "jit_env_step = jax.jit(env.step)\n",
    "#jit_inference_fn = jax.jit(inference_fn)\n",
    "\n",
    "rollout = []\n",
    "rng = jax.random.PRNGKey(seed=0)\n",
    "state = jit_env_reset(rng=rng)\n",
    "h = np.zeros_like(state.obs)\n",
    "r = []\n",
    "\n",
    "while not state.done:\n",
    "  rollout.append(state)\n",
    "  r.append(state.reward)\n",
    "  h, act = jit_inference_fn(params, h, state.obs)\n",
    "  state = jit_env_step(state, act)\n",
    "\n",
    "print(sum(r))\n",
    "HTML(html.render(env.sys, [s.qp for s in rollout]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Brax",
   "language": "python",
   "name": "brax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
